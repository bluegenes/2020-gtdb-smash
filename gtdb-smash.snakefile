"""
Author: N. Tessa Pierce, UC Davis Lab for Data Intensive Biology
Run: snakemake -s gtdb-smash.snakefile --use-conda
"""

import os
import glob
#lineage_csv=config["lineage_csv"]

output_extensions = ["sig"]
output_targets, genome_targets, translate_targets, rna_targets, protein_targets = [],[],[],[],[]

out_dir = config.get("out_dir", "output-gtdb-smash")
data_dir= os.path.join(out_dir, "data")
logs_dir = os.path.join(out_dir, "logs")
compute_dir = os.path.join(out_dir, "compute")
gtdb_datadir = config.get("gtdb_datadir", "/home/ctbrown/gtdbtk/release89/fastani/database")
gtdb_protein_datadir = config.get("gtdb_protein_datadir", "")

translate_dna = config.get("translate_dna", False)
protein_input = config.get("protein_input", False)
encoding_info = config["sourmash_params"]["encoding"]

genome_lineage_list =config["genome_lineage_list"] # generated by extract-robust-lineages
genome_extension = "_genomic.fna.gz"
genome_lineages = [line.strip().split(genome_extension)[0] for line in open(genome_lineage_list)][:10]
dna_params = encoding_info["dna"]
if config.get("genome_sigs", True):
    genome_targets = expand(os.path.join(compute_dir, "{encoding}", "{sample}_{encoding}_scaled{scaled}_k{k}.{ext}"), sample = genome_lineages, encoding="dna", scaled=dna_params["scaled"], k=dna_params["ksize"], ext=output_extensions)
    if translate_dna:
        # _how_ bad is it to directly translate genomes?
        for encoding in ["protein", "dayhoff", "hp"]:
            # ksizes must be multiplied by 3 (give nucleotide ksizes to sourmash)
            translate_ksizes = [int(k)*3 for k in encoding_info[encoding]["ksize"]]
            translate_targets+=expand(os.path.join(compute_dir, "dna","{sample}_{encoding}_scaled{scaled}_k{k}.{ext}"), sample = genome_lineages, encoding=encoding, scaled=encoding_info[encoding]["scaled"], k=translate_ksizes, ext=output_extensions)

if protein_input:
    for encoding in ["protein", "dayhoff", "hp"]:
        protein_targets+=expand(os.path.join(compute_dir,"protein","{sample}_{encoding}_scaled{scaled}_k{k}.{ext}"), sample = genome_lineages, encoding=encoding, scaled=encoding_info[encoding]["scaled"],k=encoding_info[encoding]["ksize"], ext=output_extensions)

output_targets = genome_targets + rna_targets + protein_targets + translate_targets

rule all:
    input: output_targets

localrules: get_genomes, get_proteins

rule get_genomes:
    input: os.path.join(gtdb_datadir, "{sample}_genomic.fna.gz")
    output: os.path.join(data_dir, "{sample}_genomic.fna.gz") 
    shell: 
        """    
        cp {input} {output}
        """

# too many - don't want to copy all over!
#rule get_proteins:
    #input: find_corresponding_protein_file 
    #output: os.path.join(data_dir, "{sample}_protein.faa.gz")
    #shell:
    #    """
    #    cp {input} {output}
    #    """

rule sourmash_compute_dna:
    input: rules.get_genomes.output
    output: os.path.join(compute_dir, "dna", "{sample}_{encoding}_scaled{scaled}_k{k}.sig")
    params:
        k= lambda w: w.k,
        scaled= lambda w: w.scaled,
        compute_moltypes= lambda w: w.encoding,
        input_is_protein=False,
        track_abundance=True,
    threads: 1
    resources:
        #mem_mb=3000,
        mem_mb=lambda wildcards, attempt: attempt *3000,
        runtime=200,
    log: os.path.join(logs_dir, "sourmash", "{sample}_{encoding}_scaled{scaled}_k{k}.dna.compute.log")
    benchmark: os.path.join(logs_dir, "sourmash", "{sample}_{encoding}_scaled{scaled}_k{k}.dna.compute.benchmark")
    conda: "envs/sourmash3.3.yml"
    script: "scripts/sourmash-compute.wrapper.py"

def find_corresponding_protein_file(w):
    return glob.glob(os.path.join(gtdb_protein_datadir, "*", f"*{w.sample}*"))

rule sourmash_compute_protein:
    input: find_corresponding_protein_file 
    output: os.path.join(compute_dir, "protein", "{sample}_{encoding}_scaled{scaled}_k{k}.sig")
    params:
        k= lambda w: w.k,
        scaled= lambda w: w.scaled,
        compute_moltypes= lambda w: w.encoding,
        input_is_protein=True,
        track_abundance=True,
    threads: 1
    resources:
        #mem_mb=3000,
        mem_mb=lambda wildcards, attempt: attempt *3000,
        runtime=200,
    log: os.path.join(logs_dir, "sourmash", "{sample}_{encoding}_scaled{scaled}_k{k}.protein.compute.log")
    benchmark: os.path.join(logs_dir, "sourmash", "{sample}_{encoding}_scaled{scaled}_k{k}.protein.compute.benchmark")
    conda: "envs/sourmash3.3.yml"
    script: "scripts/sourmash-compute.wrapper.py"

